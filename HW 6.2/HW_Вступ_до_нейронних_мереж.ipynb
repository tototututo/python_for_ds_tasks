{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Секція 1. Логістична регресія з нуля.**\n",
        "\n",
        "Будемо крок за кроком будувати модель лог регресії з нуля для передбачення, чи буде врожай більше за 80 яблук (задача подібна до лекційної, але на класифікацію).\n",
        "\n",
        "Давайте нагадаємо основні формули для логістичної регресії.\n",
        "\n",
        "### Функція гіпотези - обчислення передбачення у логістичній регресії:\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\sigma(x W^T + b) = \\frac{1}{1 + e^{-(x W^T + b)}}\n",
        "$$\n",
        "\n",
        "Де:\n",
        "- $ \\hat{y} $ — це ймовірність \"позитивного\" класу.\n",
        "- $ x $ — це вектор (або матриця для набору прикладів) вхідних даних.\n",
        "- $ W $ — це вектор (або матриця) вагових коефіцієнтів моделі.\n",
        "- $ b $ — це зміщення (bias).\n",
        "- $ \\sigma(z) $ — це сигмоїдна функція активації.\n",
        "\n",
        "### Як обчислюється сигмоїдна функція:\n",
        "\n",
        "Сигмоїдна функція $ \\sigma(z) $ має вигляд:\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "Ця функція перетворює будь-яке дійсне значення $ z $ в інтервал від 0 до 1, що дозволяє інтерпретувати вихід як ймовірність для логістичної регресії.\n",
        "\n",
        "### Формула функції втрат для логістичної регресії (бінарна крос-ентропія):\n",
        "\n",
        "Функція втрат крос-ентропії оцінює, наскільки добре модель передбачає класи, порівнюючи передбачені ймовірності $ \\hat{y} $ із справжніми мітками $ y $. Формула наступна:\n",
        "\n",
        "$$\n",
        "L(y, \\hat{y}) = - \\left[ y \\cdot \\log(\\hat{y}) + (1 - y) \\cdot \\log(1 - \\hat{y}) \\right]\n",
        "$$\n",
        "\n",
        "Де:\n",
        "- $ y $ — це справжнє значення (мітка класу, 0 або 1).\n",
        "- $ \\hat{y} $ — це передбачене значення (ймовірність).\n",
        "\n"
      ],
      "metadata": {
        "id": "lbLHTNfSclli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\n",
        "Тут вже наведений код для ініціювання набору даних в форматі numpy. Перетворіть `inputs`, `targets` на `torch` тензори. Виведіть результат на екран."
      ],
      "metadata": {
        "id": "GtOYB-RHfc_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "3BNXSR-VdYKQ"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "QLKZ77x4v_-v"
      },
      "outputs": [],
      "source": [
        "# Вхідні дані (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Таргети (apples > 80)\n",
        "targets = np.array([[0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1]], dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_tensor = torch.from_numpy(inputs)\n",
        "targets_tensor = torch.from_numpy(targets)\n",
        "\n",
        "print(\"Tensor inputs:\")\n",
        "print(inputs_tensor)\n",
        "print(\"\\nTensor targets:\")\n",
        "print(targets_tensor)"
      ],
      "metadata": {
        "id": "KjoeaDrk6fO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5892e2ef-2fd2-49d5-a143-6b4b4bb66acc"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor inputs:\n",
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "\n",
            "Tensor targets:\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Ініціюйте ваги `w`, `b` для моделі логістичної регресії потрібної форми зважаючи на розмірності даних випадковими значеннями з нормального розподілу. Лишаю тут код для фіксації `random_seed`."
      ],
      "metadata": {
        "id": "iKzbJKfOgGV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.random.manual_seed(1)"
      ],
      "metadata": {
        "id": "aXhKw6Tdj1-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f120fb2e-79f5-4289-a698-cee2e6ab7ae2"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a3103724c30>"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = inputs_tensor.shape[1]\n",
        "output_size = 1"
      ],
      "metadata": {
        "id": "eApcB7eb6h9o"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.randn(input_size, output_size, requires_grad=True)"
      ],
      "metadata": {
        "id": "_uOg0vwasbqU"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.randn(output_size, requires_grad=True)"
      ],
      "metadata": {
        "id": "6p7dMYAKsfdP"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Вагові коефіцієнти (w, розмірність {w.shape}):\")\n",
        "print(w)\n",
        "print(f\"\\nЗміщення (b, розмірність {b.shape}):\")\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6Uy5Hn6skLs",
        "outputId": "b035e748-e915-4b86-a672-5c3a0dc2631e"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вагові коефіцієнти (w, розмірність torch.Size([3, 1])):\n",
            "tensor([[0.6614],\n",
            "        [0.2669],\n",
            "        [0.0617]], requires_grad=True)\n",
            "\n",
            "Зміщення (b, розмірність torch.Size([1])):\n",
            "tensor([0.6213], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Напишіть функцію `model`, яка буде обчислювати функцію гіпотези в логістичній регресії і дозволяти робити передбачення на основі введеного рядка даних і коефіцієнтів в змінних `w`, `b`.\n",
        "\n",
        "  **Важливий момент**, що функція `model` робить обчислення на `torch.tensors`, тож для математичних обчислень використовуємо фукнціонал `torch`, наприклад:\n",
        "  - обчсилення $e^x$: `torch.exp(x)`\n",
        "  - обчсилення $log(x)$: `torch.log(x)`\n",
        "  - обчислення середнього значення вектору `x`: `torch.mean(x)`\n",
        "\n",
        "  Використайте функцію `model` для обчислення передбачень з поточними значеннями `w`, `b`.Виведіть результат обчислень на екран.\n",
        "\n",
        "  Проаналізуйте передбачення. Чи не викликають вони у вас підозр? І якщо викликають, то чим це може бути зумовлено?"
      ],
      "metadata": {
        "id": "nYGxNGTaf5s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(x, w, b):\n",
        "\n",
        "    # Обчислення лінійної комбінації: xW + b\n",
        "    linear_combination = x @ w + b\n",
        "\n",
        "    # Застосування сигмоїдної функції: 1 / (1 + e⁻z)\n",
        "    predictions = 1 / (1 + torch.exp(-linear_combination))\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "pSz2j4Fh6jBv"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model(inputs_tensor, w, b)\n",
        "\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVIM01IPt1gy",
        "outputId": "481693db-b1c2-4aa0-f456-f6b4a6ccca2d"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Спостереження**\n",
        "\n",
        "Отриманий результат свідчить про те, що всі передбачення моделі є 1 (ймовірність \"високого врожаю\").\n",
        "\n",
        "Думаю що це зумовлено тим що ваги були аідібрани випадково. Також в даній моделі немає ніякої оптимізації, та і фактично модель доволі наївна і робить передбачення на обум."
      ],
      "metadata": {
        "id": "tr7s2FlMuVx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Напишіть функцію `binary_cross_entropy`, яка приймає на вхід передбачення моделі `predicted_probs` та справжні мітки в даних `true_labels` і обчислює значення втрат (loss)  за формулою бінарної крос-ентропії для кожного екземпляра та вертає середні втрати по всьому набору даних.\n",
        "  Використайте функцію `binary_cross_entropy` для обчислення втрат для поточних передбачень моделі."
      ],
      "metadata": {
        "id": "O2AGM0Mb2yHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_cross_entropy(predicted_probs, true_labels):\n",
        "\n",
        "    epsilon = 1e-7\n",
        "\n",
        "    # Обчислення першого доданку: y * log(ŷ)\n",
        "    term_1 = true_labels * torch.log(predicted_probs + epsilon)\n",
        "\n",
        "    # Обчислення другого доданку: (1 - y) * log(1 - ŷ)\n",
        "    term_2 = (1 - true_labels) * torch.log(1 - predicted_probs + epsilon)\n",
        "\n",
        "    # Сума двох доданків, помножена на -1 (втрати для кожного екземпляра)\n",
        "    loss_per_example = - (term_1 + term_2)\n",
        "\n",
        "    # Повернення середніх втрат по всьому набору даних\n",
        "    average_loss = torch.mean(loss_per_example)\n",
        "\n",
        "    return average_loss"
      ],
      "metadata": {
        "id": "1bWlovvx6kZS"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = binary_cross_entropy(predictions, targets_tensor)\n",
        "\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4W6Pz8owKkt",
        "outputId": "84e6ee54-ef1c-4081-8f9d-cfde606db1fd"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.4472, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Зробіть зворотнє поширення помилки і виведіть градієнти за параметрами `w`, `b`. Проаналізуйте їх значення. Як гадаєте, чому вони саме такі?"
      ],
      "metadata": {
        "id": "ZFKpQxdHi1__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not torch.isnan(loss):\n",
        "    loss.backward()\n",
        "else:\n",
        "    print(\"Зворотне поширення помилки призвело до градієнтів nan через попередній nan у функції втрат.\")\n",
        "\n",
        "print(\"Градієнти вагових коефіцієнтів (w.grad):\")\n",
        "print(w.grad)\n",
        "print(\"\\nГрадієнт зміщення (b.grad):\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "id": "YAbXUNSJ6mCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ea42021-6814-4691-a5ef-94793dd28861"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Градієнти вагових коефіцієнтів (w.grad):\n",
            "tensor([[1.0201e-22],\n",
            "        [9.3628e-23],\n",
            "        [6.0090e-23]])\n",
            "\n",
            "Градієнт зміщення (b.grad):\n",
            "tensor([1.3974e-24])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Що сталось?**\n",
        "\n",
        "В цій задачі, коли ми ініціювали значення випадковими значеннями з нормального розподілу, насправді ці значення не були дуже гарними стартовими значеннями і привели до того, що градієнти стали дуже малими або навіть рівними нулю (це призводить до того, що градієнти \"зникають\"), і відповідно при оновленні ваг у нас не буде нічого змінюватись. Це називається `gradient vanishing`. Це відбувається через **насичення сигмоїдної функції активації.**\n",
        "\n",
        "У нашій задачі ми використовуємо сигмоїдну функцію активації, яка має такий вигляд:\n",
        "\n",
        "   $$\n",
        "   \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "   $$\n",
        "\n",
        "\n",
        "Коли значення $z$ дуже велике або дуже мале, сигмоїдна функція починає \"насичуватись\". Це означає, що для великих позитивних $z$ сигмоїда наближається до 1, а для великих негативних — до 0. В цих діапазонах градієнти починають стрімко зменшуватись і наближаються до нуля (бо градієнт - це похідна, похідна на проміжку функції, де вона паралельна осі ОХ, дорівнює 0), що робить оновлення ваг неможливим.\n",
        "\n",
        "![](https://editor.analyticsvidhya.com/uploads/27889vaegp.png)\n",
        "\n",
        "У логістичній регресії $ z = x \\cdot w + b $. Якщо ваги $w, b$ - великі, значення $z$ також буде великим, і сигмоїда перейде в насичену область, де градієнти дуже малі.\n",
        "\n",
        "Саме це сталося в нашій задачі, де великі випадкові значення ваг викликали насичення сигмоїдної функції. Це в свою чергу призводить до того, що під час зворотного поширення помилки (backpropagation) модель оновлює ваги дуже повільно або зовсім не оновлює. Це називається проблемою **зникнення градієнтів** (gradient vanishing problem).\n",
        "\n",
        "**Що ж робити?**\n",
        "Ініціювати ваги маленькими значеннями навколо нуля. Наприклад ми можемо просто в існуючій ініціалізації ваги розділити на 1000. Можна також використати інший спосіб ініціалізації вагів - інформація про це [тут](https://www.geeksforgeeks.org/initialize-weights-in-pytorch/).\n",
        "\n",
        "Як це робити - показую нижче. **Виконайте код та знову обчисліть передбачення, лосс і виведіть градієнти.**\n",
        "\n",
        "А я пишу пояснення, чому просто не зробити\n",
        "\n",
        "```\n",
        "w = torch.randn(1, 3, requires_grad=True)/1000\n",
        "b = torch.randn(1, requires_grad=True)/1000\n",
        "```\n",
        "\n",
        "Нам потрібно, аби тензори вагів були листовими (leaf tensors).\n",
        "\n",
        "1. **Що таке листовий тензор**\n",
        "Листовий тензор — це тензор, який був створений користувачем безпосередньо і з якого починається обчислювальний граф. Якщо такий тензор має `requires_grad=True`, PyTorch буде відслідковувати всі операції, виконані над ним, щоб правильно обчислювати градієнти під час навчання.\n",
        "\n",
        "2. **Чому ми використовуємо `w.data` замість звичайних операцій**\n",
        "Якщо ми просто виконали б операції, такі як `(w - 0.5) / 100`, ми б отримали **новий тензор**, який вже не був би листовим тензором, оскільки ці операції створюють **новий** тензор, а не модифікують існуючий.\n",
        "\n",
        "  Проте, щоб залишити наші тензори ваги `w` та зміщення `b` листовими і продовжити можливість відстеження градієнтів під час тренування, ми використовуємо атрибут `.data`. Цей атрибут дозволяє **виконувати операції in-place (прямо на існуючому тензорі)** без зміни самого об'єкта тензора. Отже, тензор залишається листовим, і PyTorch може коректно обчислювати його градієнти.\n",
        "\n",
        "3. **Чому важливо залишити тензор листовим**\n",
        "Якщо тензор більше не є листовим (наприклад, через проведення операцій, що створюють нові тензори), ви не зможете отримати градієнти за допомогою `w.grad` чи `b.grad` після виклику `loss.backward()`. Це може призвести до втрати можливості оновлення параметрів під час тренування моделі. В нашому випадку ми хочемо, щоб тензори `w` та `b` накопичували градієнти, тому вони повинні залишатись листовими.\n",
        "\n",
        "**Висновок:**\n",
        "Ми використовуємо `.data`, щоб виконати операції зміни значень на ваги і зміщення **in-place**, залишаючи їх листовими тензорами, які можуть накопичувати градієнти під час навчання. Це дозволяє коректно працювати механізму зворотного поширення помилки (backpropagation) і оновлювати ваги моделі."
      ],
      "metadata": {
        "id": "nDN1t1RujQsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Виконайте код та знову обчисліть передбачення, лосс і знайдіть градієнти та виведіть всі ці тензори на екран."
      ],
      "metadata": {
        "id": "rOPSQyttpVjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.random.manual_seed(1)\n",
        "w = torch.randn(1, 3, requires_grad=True)  # Листовий тензор\n",
        "b = torch.randn(1, requires_grad=True)     # Листовий тензор\n",
        "\n",
        "# in-place операції\n",
        "w.data = w.data / 1000\n",
        "b.data = b.data / 1000"
      ],
      "metadata": {
        "id": "-EBOJ3tsnRaD"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Нові Ваги w:\\n{w}\")\n",
        "print(f\"Нове Зміщення b:\\n{b}\")"
      ],
      "metadata": {
        "id": "-JwXiSpX6orh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b8a586-0c12-40f2-ddbe-978e51d8c7bb"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Нові Ваги w:\n",
            "tensor([[6.6135e-04, 2.6692e-04, 6.1677e-05]], requires_grad=True)\n",
            "Нове Зміщення b:\n",
            "tensor([0.0006], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model(inputs_tensor, w.T, b)\n",
        "\n",
        "loss = binary_cross_entropy(predictions, targets_tensor)\n",
        "\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "VCQqOSh_yWM7"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"Обчислені передбачення:\\n{predictions}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"Обчислені середні втрати:\\n{loss}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"Градієнти вагових коефіцієнтів:\\n{w.grad}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"Градієнт зміщення:\\n{b.grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LilIDvvYydeZ",
        "outputId": "c6710a54-b3d6-42a3-f099-4dcc17be7c4c"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Обчислені передбачення:\n",
            "tensor([[0.5174],\n",
            "        [0.5220],\n",
            "        [0.5244],\n",
            "        [0.5204],\n",
            "        [0.5190]], grad_fn=<MulBackward0>)\n",
            "\n",
            "==================================================\n",
            "Обчислені середні втрати:\n",
            "0.6829455494880676\n",
            "\n",
            "==================================================\n",
            "Градієнти вагових коефіцієнтів:\n",
            "tensor([[ -5.4417, -18.9853, -10.0682]])\n",
            "\n",
            "==================================================\n",
            "Градієнт зміщення:\n",
            "tensor([-0.0794])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Напишіть алгоритм градієнтного спуску, який буде навчати модель з використанням написаних раніше функцій і виконуючи оновлення ваг. Алгоритм має включати наступні кроки:\n",
        "\n",
        "  1. Генерація прогнозів\n",
        "  2. Обчислення втрат\n",
        "  3. Обчислення градієнтів (gradients) loss-фукнції відносно ваг і зсувів\n",
        "  4. Налаштування ваг шляхом віднімання невеликої величини, пропорційної градієнту (`learning_rate` домножений на градієнт)\n",
        "  5. Скидання градієнтів на нуль\n",
        "\n",
        "Виконайте градієнтний спуск протягом 1000 епох, обчисліть фінальні передбачення і проаналізуйте, чи вони точні?"
      ],
      "metadata": {
        "id": "RCdi44IT334o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "num_epochs = 1000\n",
        "loss_history = []"
      ],
      "metadata": {
        "id": "mObHPyE06qsO"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Початок навчання (Епох: {num_epochs}, LR: {learning_rate})\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # 1. Генерація прогнозів (Пряме поширення / Forward Pass)\n",
        "    predictions = model(inputs_tensor, w.T, b)\n",
        "\n",
        "    # 2. Обчислення втрат\n",
        "    loss = binary_cross_entropy(predictions, targets_tensor)\n",
        "    loss_history.append(loss.item())\n",
        "\n",
        "    # 3. Обчислення градієнтів (Зворотне поширення / Backward Pass)\n",
        "    loss.backward()\n",
        "\n",
        "    # 4. Налаштування ваг\n",
        "    # Блокуємо відстеження градієнтів для операції оновлення (.data)\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "        b -= learning_rate * b.grad\n",
        "\n",
        "    # 5. Скидання градієнтів на нуль\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "    # Виведення прогресу\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Епоха [{epoch+1}/{num_epochs}], Втрати: {loss.item():.6f}')\n",
        "\n",
        "print(\"Навчання завершено!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8lJjzL_1hCg",
        "outputId": "35b36885-67b2-48ef-f8a3-4ef7b64f227e"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Початок навчання (Епох: 1000, LR: 0.01)\n",
            "Епоха [100/1000], Втрати: 6.447238\n",
            "Епоха [200/1000], Втрати: 6.447238\n",
            "Епоха [300/1000], Втрати: 6.447238\n",
            "Епоха [400/1000], Втрати: 6.447238\n",
            "Епоха [500/1000], Втрати: 6.447238\n",
            "Епоха [600/1000], Втрати: 6.447238\n",
            "Епоха [700/1000], Втрати: 6.447238\n",
            "Епоха [800/1000], Втрати: 6.447238\n",
            "Епоха [900/1000], Втрати: 6.447238\n",
            "Епоха [1000/1000], Втрати: 6.447238\n",
            "Навчання завершено!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_predictions = model(inputs_tensor, w.T, b)\n",
        "\n",
        "final_classes = (final_predictions >= 0.5).long()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Фінальні Результати:\")\n",
        "print(f\"Справжні мітки:\\n{targets_tensor.T}\")\n",
        "print(f\"Фінальні ймовірності:\\n{final_predictions.data.T}\")\n",
        "print(f\"Фінальні класи:\\n{final_classes.data.T}\")\n",
        "print(f\"Фінальні втрати: {loss.item():.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zda-RTVG1kAR",
        "outputId": "00efc646-5ff3-442b-9117-4aefa279fe9d"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Фінальні Результати:\n",
            "Справжні мітки:\n",
            "tensor([[0., 1., 1., 0., 1.]])\n",
            "Фінальні ймовірності:\n",
            "tensor([[1., 1., 1., 1., 1.]])\n",
            "Фінальні класи:\n",
            "tensor([[1, 1, 1, 1, 1]])\n",
            "Фінальні втрати: 6.447238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Спостереження**\n",
        "\n",
        "Отриманий результат показує, що навчання не відбулося і модель \"застрягла\" на самому початку.\n",
        "\n",
        "Трохи розчаровує, бо не зовсім розумію чи це очікувано?"
      ],
      "metadata": {
        "id": "Ejwfe8jl4b7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Секція 2. Створення лог регресії з використанням функціоналу `torch.nn`.**\n",
        "\n",
        "Давайте повторно реалізуємо ту ж модель, використовуючи деякі вбудовані функції та класи з PyTorch.\n",
        "\n",
        "Даних у нас буде побільше - тож, визначаємо нові масиви."
      ],
      "metadata": {
        "id": "fuRhlyF9qAia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Вхідні дані (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70],\n",
        "                   [73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70],\n",
        "                   [73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Таргети (apples > 80)\n",
        "targets = np.array([[0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1]], dtype='float32')"
      ],
      "metadata": {
        "id": "IX8Bhm74rV4M"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Завантажте вхідні дані та мітки в PyTorch тензори та з них створіть датасет, який поєднує вхідні дані з мітками, використовуючи клас `TensorDataset`. Виведіть перші 3 елементи в датасеті.\n",
        "\n"
      ],
      "metadata": {
        "id": "7X2dV30KtAPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "inputs_tensor = torch.from_numpy(inputs)\n",
        "targets_tensor = torch.from_numpy(targets)\n",
        "\n",
        "mean_inputs = inputs_tensor.mean(dim=0)\n",
        "std_inputs = inputs_tensor.std(dim=0)\n",
        "\n",
        "std_inputs[std_inputs == 0] = 1.0\n",
        "inputs_tensor_norm = (inputs_tensor - mean_inputs) / std_inputs"
      ],
      "metadata": {
        "id": "chrvMfBs6vjo"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(inputs_tensor_norm, targets_tensor)\n",
        "\n",
        "print(f\"Загальна кількість елементів у датасеті: {len(dataset)}\")\n",
        "print(f\"Розмірність нормалізованих вхідних даних: {inputs_tensor_norm.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYumn3i06LLE",
        "outputId": "288d28b7-45aa-48b1-b0c8-170c0f263983"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загальна кількість елементів у датасеті: 15\n",
            "Розмірність нормалізованих вхідних даних: torch.Size([15, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(f\"Елемент {i+1}: {dataset[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Wcl3HRU6QWY",
        "outputId": "be4771bc-7fdf-4e51-b427-4f951a1669b3"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Елемент 1: (tensor([-0.9132, -0.5913, -0.8811]), tensor([0.]))\n",
            "Елемент 2: (tensor([0.5287, 0.0763, 0.7420]), tensor([1.]))\n",
            "Елемент 3: (tensor([0.2083, 1.5387, 0.2782]), tensor([1.]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Визначте data loader з класом **DataLoader** для підготовленого датасету `train_ds`, встановіть розмір батчу на 5 та увімкніть перемішування даних для ефективного навчання моделі. Виведіть перший елемент в дата лоадері."
      ],
      "metadata": {
        "id": "4nMFaa8suOd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "batch_size = 5\n",
        "\n",
        "train_dl = DataLoader(dataset, batch_size, shuffle=True)\n",
        "\n",
        "print(f\"Розмір батчу: {batch_size}\")\n",
        "print(f\"Загальна кількість батчів: {len(train_dl)}\")"
      ],
      "metadata": {
        "id": "ZCsRo5Mx6wEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d308a79-1d22-479e-9543-8114c2687c13"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Розмір батчу: 5\n",
            "Загальна кількість батчів: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for xb, yb in train_dl:\n",
        "    print(\"\\nПерший елемент (міні-батч) у DataLoader:\")\n",
        "    print(f\"Розмірність вхідних даних батчу: {xb.shape}\")\n",
        "    print(f\"Розмірність міток батчу: {yb.shape}\")\n",
        "    print(\"\\nПерші 3 рядки вхідних даних (xb):\")\n",
        "    print(xb[:3].detach().numpy().round(4))\n",
        "    print(\"\\nВідповідні мітки (yb):\")\n",
        "    print(yb.T)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub2zVpdp6iEA",
        "outputId": "b4670aca-014a-4ae5-ca82-7f73ea6458c6"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Перший елемент (міні-батч) у DataLoader:\n",
            "Розмірність вхідних даних батчу: torch.Size([5, 3])\n",
            "Розмірність міток батчу: torch.Size([5, 1])\n",
            "\n",
            "Перші 3 рядки вхідних даних (xb):\n",
            "[[-0.9132 -0.5913 -0.8811]\n",
            " [ 0.5287  0.0763  0.742 ]\n",
            " [ 1.4099 -1.3543 -1.3448]]\n",
            "\n",
            "Відповідні мітки (yb):\n",
            "tensor([[0., 1., 0., 1., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Створіть клас `LogReg` для логістичної регресії, наслідуючи модуль `torch.nn.Module` за прикладом в лекції (в частині про FeedForward мережі).\n",
        "\n",
        "  У нас модель складається з лінійної комбінації вхідних значень і застосування фукнції сигмоїда. Тож, нейромережа буде складатись з лінійного шару `nn.Linear` і використання активації `nn.Sigmid`. У створеному класі мають бути реалізовані методи `__init__` з ініціалізацією шарів і метод `forward` для виконання прямого проходу моделі через лінійний шар і функцію активації.\n",
        "\n",
        "  Створіть екземпляр класу `LogReg` в змінній `model`."
      ],
      "metadata": {
        "id": "ymcQOo_hum6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LogReg(nn.Module):\n",
        "\n",
        "    # 1. Ініціалізація шарів\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "\n",
        "        # Лінійний шар: обчислює xW + b\n",
        "        # Тут torch.nn.Linear автоматично ініціалізує ваги (W) та зміщення (b)\n",
        "        self.linear = nn.Linear(input_size, output_size)\n",
        "\n",
        "        # Функція активації: застосовує сигмоїду (σ) до результату лінійного шару\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # 2. Пряме поширення (виконання обчислення)\n",
        "    def forward(self, x):\n",
        "        # 1. Обчислення лінійної комбінації\n",
        "        z = self.linear(x)\n",
        "\n",
        "        # 2. Застосування сигмоїди для отримання ймовірності (ŷ)\n",
        "        predictions = self.sigmoid(z)\n",
        "\n",
        "        return predictions"
      ],
      "metadata": {
        "id": "EyAwhTBW6xxz"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogReg(input_size, output_size)"
      ],
      "metadata": {
        "id": "zoKfyxrr72cK"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Екземпляр моделі: {model}\")\n",
        "print(\"\\nПараметри моделі:\")\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name} (розмірність): {param.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9cRWzp2758d",
        "outputId": "47fc1cee-1602-4786-845b-f12fa90c5bc6"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Екземпляр моделі: LogReg(\n",
            "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Параметри моделі:\n",
            "linear.weight (розмірність): torch.Size([1, 3])\n",
            "linear.bias (розмірність): torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Задайте оптимізатор `Stockastic Gradient Descent` в змінній `opt` для навчання моделі логістичної регресії. А також визначіть в змінній `loss` функцію втрат `binary_cross_entropy` з модуля `torch.nn.functional` для обчислення втрат моделі. Обчисліть втрати для поточних передбачень і міток, а потім виведіть їх. Зробіть висновок, чи моделі вдалось навчитись?"
      ],
      "metadata": {
        "id": "RflV7xeVyoJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "learning_rate = 0.01\n",
        "opt = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = F.binary_cross_entropy\n",
        "\n",
        "print(f\"Оптимізатор: {opt}\")\n",
        "print(f\"Функція втрат: {loss_fn}\")"
      ],
      "metadata": {
        "id": "3QCATPU_6yfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5976a368-a080-4f71-815c-c34896158afd"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оптимізатор: SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "Функція втрат: <function binary_cross_entropy at 0x7a31007df740>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = next(iter(train_dl))\n",
        "\n",
        "predictions = model(xb)\n",
        "\n",
        "loss = loss_fn(predictions, yb)\n",
        "\n",
        "print(f\"Loss: {loss.item():.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPSecVp58Z0w",
        "outputId": "335aecd8-612a-4db8-f708-e75c0ef8a916"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.834318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expected_initial_loss = np.log(2)\n",
        "\n",
        "print(f\"Початкова втрата ({loss.item():.6f}) близька до {expected_initial_loss:.6f}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIhYB1U08gy3",
        "outputId": "2a3dd593-7b09-46ce-d988-1f8ad59d9b24"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Початкова втрата (0.834318) близька до 0.693147.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Спостереження**\n",
        "\n",
        "Ваші початкові втрати становлять 0.501577, що значно нижче, ніж очікувані 0.693147 (втрати, коли модель передбачає 0.5 для всіх прикладів).\n",
        "\n",
        "Модель все ще знаходиться на початковому етапі, але вже чисельно стабільна і готова до коректного запуску циклу градієнтного спуску."
      ],
      "metadata": {
        "id": "98hrNqQy83AT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Візьміть з лекції функцію для тренування моделі з відстеженням значень втрат і навчіть щойно визначену модель на 1000 епохах. Виведіть після цього графік зміни loss, фінальні передбачення і значення таргетів."
      ],
      "metadata": {
        "id": "ch-WrYnKzMzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_return_loss(num_epochs, model, loss_fn, opt, train_dl):\n",
        "    losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        # Ініціалізуємо акумулятор для втрат\n",
        "        total_loss = 0\n",
        "\n",
        "        for xb, yb in train_dl:\n",
        "            # Генеруємо передбачення\n",
        "            pred = model(xb)\n",
        "\n",
        "            # Обчислюємо втрати\n",
        "            loss = loss_fn(pred, yb)\n",
        "\n",
        "            # Виконуємо градієнтний спуск\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "            # Накопичуємо втрати\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Обчислюємо середні втрати для епохи\n",
        "        avg_loss = total_loss / len(train_dl)\n",
        "        losses.append(avg_loss)\n",
        "\n",
        "        # Виводимо підсумок епохи\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "          print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "    return losses"
      ],
      "metadata": {
        "id": "cEHQH9qE626k"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1000\n",
        "\n",
        "print(f\"Початок навчання на {num_epochs} епохах (LR={learning_rate})\")\n",
        "history = fit_return_loss(num_epochs, model, loss_fn, opt, train_dl)\n",
        "print(\"Навчання завершено!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roR-xm2V96Uz",
        "outputId": "a926add5-7064-4647-84da-36e2dbb5a9f3"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Початок навчання на 1000 епохах (LR=0.01)\n",
            "Epoch [10/1000], Loss: 0.7140\n",
            "Epoch [20/1000], Loss: 0.6061\n",
            "Epoch [30/1000], Loss: 0.5228\n",
            "Epoch [40/1000], Loss: 0.4574\n",
            "Epoch [50/1000], Loss: 0.4057\n",
            "Epoch [60/1000], Loss: 0.3637\n",
            "Epoch [70/1000], Loss: 0.3296\n",
            "Epoch [80/1000], Loss: 0.3008\n",
            "Epoch [90/1000], Loss: 0.2768\n",
            "Epoch [100/1000], Loss: 0.2562\n",
            "Epoch [110/1000], Loss: 0.2383\n",
            "Epoch [120/1000], Loss: 0.2228\n",
            "Epoch [130/1000], Loss: 0.2092\n",
            "Epoch [140/1000], Loss: 0.1970\n",
            "Epoch [150/1000], Loss: 0.1862\n",
            "Epoch [160/1000], Loss: 0.1765\n",
            "Epoch [170/1000], Loss: 0.1677\n",
            "Epoch [180/1000], Loss: 0.1598\n",
            "Epoch [190/1000], Loss: 0.1526\n",
            "Epoch [200/1000], Loss: 0.1460\n",
            "Epoch [210/1000], Loss: 0.1399\n",
            "Epoch [220/1000], Loss: 0.1343\n",
            "Epoch [230/1000], Loss: 0.1291\n",
            "Epoch [240/1000], Loss: 0.1243\n",
            "Epoch [250/1000], Loss: 0.1199\n",
            "Epoch [260/1000], Loss: 0.1157\n",
            "Epoch [270/1000], Loss: 0.1118\n",
            "Epoch [280/1000], Loss: 0.1082\n",
            "Epoch [290/1000], Loss: 0.1048\n",
            "Epoch [300/1000], Loss: 0.1016\n",
            "Epoch [310/1000], Loss: 0.0986\n",
            "Epoch [320/1000], Loss: 0.0957\n",
            "Epoch [330/1000], Loss: 0.0930\n",
            "Epoch [340/1000], Loss: 0.0905\n",
            "Epoch [350/1000], Loss: 0.0881\n",
            "Epoch [360/1000], Loss: 0.0858\n",
            "Epoch [370/1000], Loss: 0.0836\n",
            "Epoch [380/1000], Loss: 0.0816\n",
            "Epoch [390/1000], Loss: 0.0796\n",
            "Epoch [400/1000], Loss: 0.0777\n",
            "Epoch [410/1000], Loss: 0.0759\n",
            "Epoch [420/1000], Loss: 0.0742\n",
            "Epoch [430/1000], Loss: 0.0726\n",
            "Epoch [440/1000], Loss: 0.0710\n",
            "Epoch [450/1000], Loss: 0.0695\n",
            "Epoch [460/1000], Loss: 0.0680\n",
            "Epoch [470/1000], Loss: 0.0667\n",
            "Epoch [480/1000], Loss: 0.0653\n",
            "Epoch [490/1000], Loss: 0.0640\n",
            "Epoch [500/1000], Loss: 0.0628\n",
            "Epoch [510/1000], Loss: 0.0616\n",
            "Epoch [520/1000], Loss: 0.0605\n",
            "Epoch [530/1000], Loss: 0.0594\n",
            "Epoch [540/1000], Loss: 0.0583\n",
            "Epoch [550/1000], Loss: 0.0573\n",
            "Epoch [560/1000], Loss: 0.0563\n",
            "Epoch [570/1000], Loss: 0.0553\n",
            "Epoch [580/1000], Loss: 0.0544\n",
            "Epoch [590/1000], Loss: 0.0535\n",
            "Epoch [600/1000], Loss: 0.0526\n",
            "Epoch [610/1000], Loss: 0.0518\n",
            "Epoch [620/1000], Loss: 0.0510\n",
            "Epoch [630/1000], Loss: 0.0502\n",
            "Epoch [640/1000], Loss: 0.0494\n",
            "Epoch [650/1000], Loss: 0.0487\n",
            "Epoch [660/1000], Loss: 0.0480\n",
            "Epoch [670/1000], Loss: 0.0473\n",
            "Epoch [680/1000], Loss: 0.0466\n",
            "Epoch [690/1000], Loss: 0.0459\n",
            "Epoch [700/1000], Loss: 0.0453\n",
            "Epoch [710/1000], Loss: 0.0447\n",
            "Epoch [720/1000], Loss: 0.0441\n",
            "Epoch [730/1000], Loss: 0.0435\n",
            "Epoch [740/1000], Loss: 0.0429\n",
            "Epoch [750/1000], Loss: 0.0423\n",
            "Epoch [760/1000], Loss: 0.0418\n",
            "Epoch [770/1000], Loss: 0.0412\n",
            "Epoch [780/1000], Loss: 0.0407\n",
            "Epoch [790/1000], Loss: 0.0402\n",
            "Epoch [800/1000], Loss: 0.0397\n",
            "Epoch [810/1000], Loss: 0.0392\n",
            "Epoch [820/1000], Loss: 0.0388\n",
            "Epoch [830/1000], Loss: 0.0383\n",
            "Epoch [840/1000], Loss: 0.0378\n",
            "Epoch [850/1000], Loss: 0.0374\n",
            "Epoch [860/1000], Loss: 0.0370\n",
            "Epoch [870/1000], Loss: 0.0365\n",
            "Epoch [880/1000], Loss: 0.0361\n",
            "Epoch [890/1000], Loss: 0.0357\n",
            "Epoch [900/1000], Loss: 0.0353\n",
            "Epoch [910/1000], Loss: 0.0350\n",
            "Epoch [920/1000], Loss: 0.0346\n",
            "Epoch [930/1000], Loss: 0.0342\n",
            "Epoch [940/1000], Loss: 0.0339\n",
            "Epoch [950/1000], Loss: 0.0335\n",
            "Epoch [960/1000], Loss: 0.0332\n",
            "Epoch [970/1000], Loss: 0.0328\n",
            "Epoch [980/1000], Loss: 0.0325\n",
            "Epoch [990/1000], Loss: 0.0322\n",
            "Epoch [1000/1000], Loss: 0.0318\n",
            "Навчання завершено!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history)\n",
        "plt.title(\"Зміна функції втрат (Loss) протягом 1000 епох\")\n",
        "plt.xlabel(\"Епоха\")\n",
        "plt.ylabel(\"Середні втрати (Loss)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "LcsnMiWS-BwD",
        "outputId": "7ce42bf9-2ad1-4c83-81e7-1d0c5e28932b"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_predictions_prob = model(inputs_tensor_norm)\n",
        "\n",
        "final_predictions_class = (final_predictions_prob >= 0.5).long()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ФІНАЛЬНИЙ АНАЛІЗ ПЕРЕДБАЧЕНЬ:\")\n",
        "print(f\"Справжні мітки (Targets):\\n{targets_tensor.T}\")\n",
        "print(f\"Фінальні ймовірності (Predictions):\\n{final_predictions_prob.detach().T.numpy().round(4)}\")\n",
        "print(f\"Фінальні класи (Classes):\\n{final_predictions_class.data.T}\")\n",
        "\n",
        "accuracy = (final_predictions_class == targets_tensor).float().mean()\n",
        "print(f\"\\nТочність моделі на навчальному наборі: {accuracy.item()*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRJtNnNb-ivl",
        "outputId": "151e81e1-7d25-481e-a48d-9ec57b10edbf"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "ФІНАЛЬНИЙ АНАЛІЗ ПЕРЕДБАЧЕНЬ:\n",
            "Справжні мітки (Targets):\n",
            "tensor([[0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.]])\n",
            "Фінальні ймовірності (Predictions):\n",
            "[[0.0508 0.9435 0.9831 0.0099 0.9784 0.0508 0.9435 0.9831 0.0099 0.9784\n",
            "  0.0508 0.9435 0.9831 0.0099 0.9784]]\n",
            "Фінальні класи (Classes):\n",
            "tensor([[0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1]])\n",
            "\n",
            "Точність моделі на навчальному наборі: 100.00%\n"
          ]
        }
      ]
    }
  ]
}